redis，mq,dubbo,分布式,elasticsearch

java并发，mysql,网络，JDK集合，jvm，Spring源码，tomcat，lunix，系统设计，生产实践

**hashMap对hash算法和寻址算法的优化**

hash算法：对key的hash值和hash值右移16位的值进行异或运算(^,两个数不同则为1)，对数组长度取模，得到index，高十六位和第十六位进行异或：为了低十六位有高低十六位的特征，尽量避免一些hash值后续冲突

寻址算法：得到的异或运算的值，对**数组取模**的过程进行优化

hash&(n -1) 跟对hash对n取模的效果是一样的，但是运算性能比hash取模高很多（数组的长度是2的n次方，hash对n取模 -> hash&(n-1)）

与（n-1）进行与运算，因为n-1比较小，前十六位可能都不参加与运算，所以为了保证数据的可靠性 ，需要将hash值的高十六位和低十六位进行异或 

hash值的优化是为了寻址算法的后续优化做准备，避免两个数的hash值差不多

例：

1111 1111 1111 1111 1111 1010 0111 1100 —高低异或运算—》1111 1111 1111 1111 0000 0101 1000 0011

1111 1111 1111 1110 1111 1010 0111 1100 —高低异或运算—》1111 1111 1111 1110 0000 0101 1000 0010

和（n-1）进行与运算，算出来的值就会不一样

**hashMap冲突**

会在这个位置挂一个链表，这个链表里放入多个元素

get，如果发现这个位置挂了一个链表，遍历链表，找到自己要的key-value

如果链表长度太大，遍历花费时间会很长O(n)

优化：如果链表长度达到一定的长度（拉链度：8），就 会将链表转化为红黑树，时间复杂度O(logn)

**hashMap扩容**

当数组长度满了之后，hashMap每次扩容到原来的两倍，会有一个reHash的过程，原来数组里放的数，是跟 n - 1 进行与运算的，现在要重新跟 2*n - 1进行与运算

数组长度 = 16

n-1	     0000 0000 0000 0000 0000 0000 0000 1111

hash1	1111 1111 1111 1111 0000 1111 0000 0101

&		0000 0000 0000 0000 0000 0000 0000 0101	index=5



n-1	     0000 0000 0000 0000 0000 0000 0000 1111

hash2	1111 1111 1111 1111 0000 1111 0001 0101

&		0000 0000 0000 0000 0000 0000 0000 0101	index=5

扩容到32之后，重新对每个hash值进行寻址

数组长度 = 32

n-1	     0000 0000 0000 0000 0000 0000 0001 1111

hash1	1111 1111 1111 1111 0000 1111 0000 0101

&		0000 0000 0000 0000 0000 0000 0000 0101	index=5



n-1	     0000 0000 0000 0000 0000 0000 0001 1111

hash2	1111 1111 1111 1111 0000 1111 0001 0101

&		0000 0000 0000 0000 0000 0000 0001 0101	index=21

 判断二进制结果是否多出一个bit的1，如果没有，就是原来的index，如果有，则位置位index+oldCap，避免rehash时候 ，用每个hash对新数组长度取模的性能低问题



## 并发

synchronized实现原理，CAS无锁化原理，AQS是什么，lock锁，ConcurrentHashMap的分段加锁原理，线程池原理，java内存模型，volatile是什么，对java并发包的理解

**synchronized**

synchronized 关键字底层原理跟 jvm 和 monitor 有关

用到 synchronized 关键字，底层编译后jvm指令中有monitorenter 和monitorexit 两个指令

~~~
monitorenter
//代码对应的指令
monitorexit
~~~

每个对象都有一个对应的monitor，一个类的Class也有一个monitor，如果要对对象加锁，必须获取这个对象关联的monitor的lock锁

monitor有个计数器，线程获取monitor锁，计数器加1

支持可重用加锁

~~~
synchronized(myObject){
    //代码
    synchronized(myObject){
    //代码
	}
}
~~~

**CAS的理解和原理**

synchronized对方法加锁

~~~
public Class MyObject{
    int i = 0;
    //对myObject对象
    //同一时间，只有一个线程可以进入此方法
    public synchronized void increment(){
        i++;
    }
}
MyObject myObject = new Myobject();
myObject.increment();
~~~

用此方法，线程执行是串行的，效率不高，需要排队 执行

~~~
public Class MyObject{
    AtomicInteger i = new AtomicInteger(0);//底层基于CAS实现的
    //不需要synchronized，线程 也是安全的
    public void increment(){
        i.incrementAndGet();
    }
}
MyObject myObject = new Myobject();
myObject.increment();
~~~

CAS：compare and swap

CAS的操作是原子的，针对硬件级别,主要用于累加操作

 ![](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\CAS原理图.jpg)

**ConcurrentHashMap实现线程安全的底层原理**

HashMap的底层本身是一个数组+链表(红黑树)

~~~
HashMap map = new HashMap();
//多个线程过来
//线程1过来，要 put 的位置为数组[5]，线程2过来，要 put 的位置为数组[21]
synchronized(map){
    map.put(xxxxx,xxxx);
}
~~~

如果加锁，明显不好，因为两个线程要 put 的位置并没有关系，但是一定加锁

为此，推出了ConcurrentHashMap，默认实现了线程安全的，继承自AbstractMap，和HashMap是同级关系

JDK 1.7 及以前，采用的是分段加锁

[数组1],[数组2],[数组3] -》每个数组都对应一个锁

线程1过来，要 put 的位置为数组1[5]，线程2过来，要 put 的位置为数组2[21]

互相之间的锁是不一样的

JDK 1.8 以后，做了一些优化，锁粒度细化

一个大的数组，数组每个元素进行put操作，都有一个不同的锁

如果两个线程都在对数组[5]进行put，采取的是 **CAS** 策略，如果刚刚有人放进去值了，就需要对这个位置进行基于链表+红黑树来进行处理，synchronized(数组[5])，加锁，基于链表/红黑树，在这个位置插进去自己的数据

**AQS的理解和实现原理**

AQS：Abstract Queue Synchronizer 抽象队列同步器

多线程同时访问一个共享数据，synchronized，CAS，ConcurrnetHashMap，lock等

**synchronized 和 lock() 的区别**？？（课后）

1. synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。
2. synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；
   而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。
3. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。

lock的底层基于AQS

Semaphore、其他一些并发包

~~~
ReentrantLock lock = new ReentrantLock();//默认的是非公平锁
//ReentrantLock lock = new ReentrantLock(true);//公平锁
//多线程过来尝试
lock.lock();
//代码
lock.unlock();
~~~

AQS里有个变量 state = 0，线程上锁的时候，CAS机制对state进行修改为1，加锁线程更新为当前线程，加锁失败的线程进入等待队列，将自己挂起。成功的线程执行完之后，将加锁线程置为 null，state = 0，唤醒等待队列中队列头的线程

**线程池底层原理**

构建一个线程池，让他们执行各种各样的任务，不要销毁自己，等待线程。

![](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\线程池图解.jpg)

频繁的创建线程，销毁线程，影响性能

~~~
Executorservice threadPool = Executor.newFixedThreadPool(3);//3->corePoolSize
threadPool.submit(new Callable(){
    public void run(){
        
    };
});
~~~

创建一个线程池，会自带一个队列（放任务的），此时线程池里的线程数为0；然后当有任务来的时候，先判断线程池的数是否超过corePoolSize数，如果没超，就会创建一个线程。当任务结束后，会释放线程，该线程会在队列头进行阻塞，等待获取任务。**当线程数超过corePoolSize后，任务会直接进入队列。**

当不停的提交任务，会把线程池中的线程数量创建到corePoolSize数，然后再进入队列

fixed，队列， LinkedBlockingQueue，无界阻塞队列

**线程池的核心配置参数**

创建线程池，如果不用fixed之类的线程池，自己完全可以通过构造函数创建自己的线程池，参数：corePoolSize，maximumPoolSize，keepAliveTime，queue

~~~java
return new ThreadpoolExecutor(nThreads,nThreads,0L,TimeUnit.MILLISSECONDS,new LinkedBlockingQueue<Runabble>())
~~~

corePoolSize:3

maximumPoolSize:Integer.MAX_VALUE

keepAliveTime:60s

new ArrayBlockingQueue<Runnable>(200)

作用：线程池中的线程数量达到corePoolSize之后，任务直接进队列，当队列满了之后，达到 ArrayBlockingQueue的数量，会创建新的线程来处理任务，但是不能超过maximumPoolSize的数量。当新创建出的线程没有任务处理后，keepAliveTime之后自动销毁。

如果额外线程创建完了去处理任务，队列还是满了，有新的任务来了，只能reject掉，可以传入 RejectedExecutionHandler

- AbortPolicy：抛异常
- DiscardPolicy：扔掉任务
- DiscardOldestPolicy：抛弃最旧的任务
- CallerRunsPolicy
- 自定义

根据自己的情况，考虑 corePoolSize 的数量，队列类型，最大线程数量，拒绝策略，线程释放时间来自定义线程池

一般常用的：

- fixed，不创建新的线程，队列无限，使用的相对多一点 
- 队列有限，满了之后创建新的线程无线

![](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\线程池工作原理.jpg)

**线程池中使用无界阻塞队列会怎样**

面试题：在远程服务异常的情况下，使用无界阻塞队列，会导致内存异常飙升吗？

调用服务失败，会等超时，导致队列里的任务积压，因为队列无界，会越来越大。队列越来越大，必然导致内存飙升起来，还会导致OOM内存溢出

**线程池中的队列满了之后，会发生什么**

有界队列，可以避免内存溢出。

corePoolSize:3

maximumPoolSize:Integer.MAX_VALUE

new ArrayBlockingQueue<Runnable>(200)

假设可以不停创建线程，队列满了，新的任务进来，线程一直创建。每个线程都有自己的栈内存，会导致资源耗尽或者cpu load 负载高

无限队列和无线线程都可能会有内存溢出问题，可以根据自己的实际情况，自定义reject策略

> 如果线程池无法执行更多的任务了，此时建议你可以b把这个任务持久化写入磁盘，后台专门启动一个线程，后续等线程池的工作负载低了，它可以慢慢从磁盘读取之前持久化的任务，重新提交到线程池里去执行

**线上机器突然宕机，线程池阻塞队列中的请求怎么办**

宕机，线程池里的积压的任务实际上必然丢失的

如果说提交一个任务，提交前，现在数据库里插入任务的信息，更新他的状态：未提交，已提交，已完成。提交成功后更新他的状态为已提交。

系统重启，后台线程去扫描数据库里的信息，读取出来重新提交，继续执行



#### JVM

**java内存模型的理解**

read,load,use,assign,store,write

```
public Class HelloWorld{
	private int i;
	public void intcrement(){
		i++;
	}
}

HelloWorld h = new HelloWorld();
//线程1
new Thread(){
	new run(){
		h.intcrement();
	}
}.start;
//线程2
new Thread(){
	new run(){
		h.intcrement();
	}
}.start;
```



![1584149271232](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\data++内存模型.png)

**java内存模型的原子性、有序性、可见性**

连环泡：java内存模型->原子性、有序性、可见性->volatile->happens-before/内存屏障

可见性：

~~~
new Thread(){
	public void run(){
	data++;
	}
}.start();

new Thread(){
	public void run(){
	while(data == 0)
		Thread.sleep(1000); 
	}
}.start();
~~~

![1584193375105](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\可见性内存模型.png)

没有可见性：线程1已经更新了，但是线程2之前读取了data存在工作内存中，之后主内存已经更新了，但是线程2没有读取到，依旧在while循环里，这就是不可见。

可见性：线程1更新之后，强制要求线程2读取新的值

原子性：

线程1执行完了read、load、use、assign、store、write之后，线程2 才能执行。

data++必须独立执行，没有人影响我，一定是我自己执行成功之后，别人才能接着执行。

有序性：

~~~
flag = flase;
//线程1 
prepare();
flag=true;
//线程2
while(!flag){
	Thread.sleep(1000);
}
execute();//基于准备的资源执行操作
~~~

 有时候为了提高代码执行效率，会出现指令重排序，导致代码可能会出现一些问题。

有序性：代码不会发生重排。

**从java底层聊聊volatile关键字的原理**

volatile关键字是用来解决可见性和有序性，在有些罕见的条件下，可以有限的保证有限性，保证原子性。

~~~
private volatile int data = 0;
new Thread(){
	public void run(){
	data++;
	}
}.start();

new Thread(){
	public void run(){
	while(data == 0)
		Thread.sleep(1000); 
	}
}.start();
~~~

刷到主内存的同时，会将线程2的工作内存的data失效，下次线程2会重新从主内存里加载值。

很多的开源中间件的源码大量使用了volatile。

开源中间件，大数据系统，都多线程并发，volatile

~~~
public class Kafka{
	pirvate volatile boolean running = true;
	//他是一个接口
	public void shutdown(){
	//关闭这个系统，有个shutdown.sh脚本，来调用这个shutdown接口
		running = false；
	}
	public static void main(){
		//启动kafka，rockemeq，会有一大堆的代码，中间件系统，不能直接退出
		Kafka kafka = new Kafka();
		while(kafka.running){
			Thread.sleep(1000);
		}
	}
}
~~~

主要作用：有线程更新data，有线程读，能够保证可见性

# Spring

## Spring IoC

![](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\Spring Ioc图解.jpg)

依赖注入，控制反转

有个 Spring 容器，启动 Tomcat 的时候，根据 xml 配置，或者你的注解，实例化你的一些 bean 对象，根据 xml 配置或者注解，对 bean 对象之间的引用关系，去进行依赖注入。

底层的核心技术，反射，会通过反射的技术，直接根据你的类去构建对应的对象出来。

贡献：系统的类与类之间彻底的解耦

## Spring AOP

spring 已经管理了我们代码里所有的类的对象实例，备案
事务控制，日志管理等做一个切面，减少重复性代码的编写，再所有方法开始结束异常织入这些重复代码
AOP的核心技术：动态代理

定义好要织入代码的类和方法，在注入之后，spring会对需要代理的对象生成相应的动态代理类，他们实现一样的接口，之后再把代理类注入到原来的类中，代码所见到的是非代理类，实际运行走的是代理类里的方法。

## cjlib 和 jdk 动态代理的区别

动态的创建一个代理类，创建这个代理类的实例对象，负责一些代码的增强
如果类实现了某个接口，aop 会使用 jdk 动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk 动态代理，其实是在你的类有接口的时候会使用

很多时候某个类没有实现接口，aop 会改用 cglib 动态代理，他会生成你的类的一个子类，动态生成字节码，覆盖你的一些方法，在方法里加入增强代码

## Spring 的 Bean 是线程安全的嘛

bean 可以分为 5个范围：

- singleton：默认，一个容器只有一个 bean 实例
- prototype：为每一个 bean 请求一个实例
- request：每一个网络请求创建一个实例，请求完成后，bean 失效并被垃圾回收器回收
- session：与 request 范围类似，确保每个 session 中有一个 bean，session 过期后，bean 会失效
- global-session

一般主要用的由 singleton 和prototype，99.99%的用 singleton

不是线程安全的，可能出现多线程并发访问同一个bean。

![1585577220087](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\Spring的Bean是否安全.png)

一般来说很少在 spring bean中放实例变量。主要是组件相互调用，最终访问数据库。

大部分情况是 tomcat多个线程并发的访问数据库

![1585577655669](E:\Java\new_Java_Study\daily_notes\pictures\面试突击\Spring bean对象大部分用途.png)

## Spring 事务实现原理，事务传播机制

 @Transactional（propagation = Propagation.REQUIRED）

spirng 会使用 AOP 思想，对方法执行之前，织入开启事务的代码，执行完毕之后，根据是否报错来决定提交还是回滚事务

<font color=ff0000>事务传播机制</font>

- <font color=ff0000>Propagation.REQUIRED</font>

  如果当前没有事务，就会开启新的事务，如果有事务，就会直接加入该事务中

- Propagation.SUPPORTS

  如果有事务，就会直接加入该事务中,如果当前没有事务，就以非事务执行

- Propagation.MANDATORY

  如果有事务，就会直接加入该事务中,如果当前没有事务，就抛出异常。

- <font color=ff00ff>PROPAGATION．REQUIRES_NEW</font>

  新建事务，如果当前存在事务，把当前事务挂起，执行当前新建事务完成以后，上下文事务恢复再执

- PROPAGATION．NOT_SUPPORTED

  以非事务方式执行操作，如果当前存在事务，就把当前事务挂起，执行当前逻辑，结束后恢复上下文的事务

- PROPAGATION．NEVER

  以非事务方式执行，如果当前存在事务，则抛出异常。

- <font color=ff00ff>PROPAGATION．NESTED</font>

  如果当前存在事务，则嵌套事务内执行，如果没有事务，按照 REQUIRED 执行

  > A调用B，A 事务级别：REQUIRED
  >
  > 开启一个事务
  >
  > 执行方法 A 的一些代码 doPre()
  >
  > 设置回滚点 savePoint
  >
  > 执行 B 的一些代码
  >
  > 如果 B 报错，则此时回滚到 savePoint
  >
  > 执行 A 的一些代码，doPost()
  >
  > 提交或者回滚，回滚会连带 B 的事务一起回滚

  外层事务回滚会导致内层事务也回滚；内层事务回滚不会导致外层事务回滚

例：方法 A 调用方法 Ｂ，希望 A 出错只回滚 A，不能回滚Ｂ

​		使用　REQUIRES_NEW　传播机制，让他们的事务不同

例：方法 A 调用方法 Ｂ，希望出错后，Ｂ只回滚自己，Ａ可以带着Ｂ一起回滚

​		使用　NESTED　传播机制